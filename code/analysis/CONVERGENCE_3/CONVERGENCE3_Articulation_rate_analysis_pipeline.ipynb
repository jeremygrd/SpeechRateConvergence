{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995bf198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from natsort import natsorted\n",
    "import base64\n",
    "import os\n",
    "import shutil\n",
    "import soundfile as sf\n",
    "from natsort import natsorted\n",
    "import textract\n",
    "import textgrids\n",
    "#import subprocess\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eded85",
   "metadata": {},
   "outputs": [],
   "source": [
    "sujs = os.listdir(\"C:\\\\Users\\\\Jeremy\\\\Desktop\\\\CONVERGENCE3_DATA_ANALYSIS\\\\data_prolific\\\\RAW\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d87a5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sujs[50::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feed35ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "suj = 'subj20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900d42b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\Jeremy\\\\Desktop\\\\CONVERGENCE3_DATA_ANALYSIS\\\\data_prolific\\\\RAW\\\\\"+suj+\".txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290a47d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data as bytes\n",
    "text = textract.process(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c90481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data by components 10 is training (should be 11 in your data as I added a component)\n",
    "len(text.splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f31a040",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingdata = json.loads(text.splitlines()[11].decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73184305",
   "metadata": {},
   "source": [
    "# Extract RAW DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49df41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# CONCATENATE DATA from all 4 blocks#\n",
    "#####################################\n",
    "\n",
    "block1data = json.loads(text.splitlines()[12].decode('utf-8'))\n",
    "block2data = json.loads(text.splitlines()[13].decode('utf-8'))\n",
    "block3data = json.loads(text.splitlines()[14].decode('utf-8'))\n",
    "block4data = json.loads(text.splitlines()[15].decode('utf-8'))\n",
    "allblocks = np.concatenate((block1data,block2data,block3data,block4data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9818e276",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# create containers for each subtype of trial#\n",
    "##############################################\n",
    "RR1s =[]\n",
    "GAPs = []\n",
    "CONVs = []\n",
    "RR2s = []\n",
    "\n",
    "# retrive trials based on their id\n",
    "trial_types = [['read&repeat1block1','read&repeat1block2','read&repeat1block3','read&repeat1block4'],\n",
    "               ['gap_answerblock1','gap_answerblock2','gap_answerblock3','gap_answerblock4'],\n",
    "               ['convergenceblock1','convergenceblock2','convergenceblock3','convergenceblock4'],\n",
    "               ['read&repeat2block1','read&repeat2block2','read&repeat2block3','read&repeat2block4']]\n",
    "trial_containers = [RR1s, GAPs,CONVs,RR2s]\n",
    "\n",
    "for num,trial in enumerate(trial_types):\n",
    "    for numi in range(len(allblocks)):\n",
    "        try:\n",
    "            if allblocks[numi]['trial_id'] in trial:\n",
    "                trial_containers[num].append(allblocks[numi])\n",
    "        except: \n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5e68b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# make sure we have the desired number of trials per subtype#\n",
    "#############################################################\n",
    "\n",
    "assert(len(RR1s)==24) #6*4\n",
    "assert(len(RR2s)==24) #6*4\n",
    "assert(len(CONVs)==32) # 8*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b953025c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in presented stimuli properties\n",
    "stim_info = pd.read_csv(\"C:\\\\Users\\\\Jeremy\\\\Documents\\\\RESEARCH\\\\PBS_2025\\\\CONVERGENCE3\\\\STIMULI\\\\stimuli_AR.csv\")\n",
    "# create dictionnary to convert filtering properties to experimental conditions\n",
    "conversion = {  '5.5_Inf': 'Normal_temporal',\n",
    "                'Inf_0.35': 'Normal_spectral' ,  \n",
    "                '23_Inf': 'Fast_temporal',\n",
    "                'Inf_1.5': 'Fast_spectral'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f0a778",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# get names and contents for CONVERGENCE#\n",
    "#########################################\n",
    "\n",
    "names_conv = []\n",
    "content_conv = []\n",
    "stims_namesconv = []\n",
    "conds2 = []\n",
    "blocks2 = []\n",
    "expcond = []\n",
    "ars = []\n",
    "shorts = []\n",
    "for num in range(len(CONVs)):\n",
    "    # get current condition\n",
    "    curxcond = CONVs[num]['presented_stim'].split('/')[1].split('filter_')[1]\n",
    "    # get current speed\n",
    "    spee = conversion[curxcond].split('_')[0]\n",
    "    # get AR from presented stim\n",
    "    curar = stim_info.loc[(stim_info['sentences'] == CONVs[num]['stimulus'].split(\"25px\\'>\")[1].split(\"</p>\")[0].lower())&(stim_info['speed'] == spee )]['articulation_rate'].values[0]\n",
    "    names_conv.append('conv_'+str(num+1)+'.wav')\n",
    "    content_conv.append(CONVs[num]['response'])\n",
    "    stims_namesconv.append(CONVs[num]['stimulus'].split(\"25px\\'>\")[1].split(\"</p>\")[0])\n",
    "    conds2.append('conv')\n",
    "    blocks2.append(CONVs[num]['trial_id'][-1])\n",
    "    expcond.append(curxcond)\n",
    "    ars.append(curar)\n",
    "    shorts.append(stim_info.loc[(stim_info['sentences'] == CONVs[num]['stimulus'].split(\"25px\\'>\")[1].split(\"</p>\")[0].lower())&(stim_info['speed'] == spee )]['short_names'].values[0])\n",
    "\n",
    "dico2 = {\n",
    "    'trial_type':conds2,\n",
    "     'audios_names':names_conv,\n",
    "    'audios_contents': content_conv,\n",
    "    'stims_names': stims_namesconv,\n",
    "    'blocks': blocks2,\n",
    "    'conditions':expcond,\n",
    "    'stim_AR': ars,\n",
    "    'short_names':shorts}\n",
    "df2 = pd.DataFrame.from_dict(dico2)\n",
    "\n",
    "\n",
    "#################################\n",
    "# get names and contents for RR1#\n",
    "#################################\n",
    "\n",
    "names_rr1 = []\n",
    "content_rr1 = []\n",
    "stims_names = []\n",
    "conds = []\n",
    "blocks = []\n",
    "expcond2 = []\n",
    "ars2 =[]\n",
    "shorts2 = []\n",
    "for num in range(len(RR1s)):\n",
    "    curb = RR1s[num]['trial_id'][-1]\n",
    "    names_rr1.append('rr1_'+str(num+1)+'.wav')\n",
    "    content_rr1.append(RR1s[num]['response'])\n",
    "    stims_names.append(RR1s[num]['stim_name'])\n",
    "    conds.append('r&r1')\n",
    "    blocks.append(curb)\n",
    "    expcond2.append(df2.loc[df2[\"blocks\"]==str(curb)]['conditions'].values[0])\n",
    "    ars2.append(np.nan)\n",
    "    shorts2.append(np.nan)\n",
    "\n",
    "dico = {\n",
    "    'trial_type':conds,\n",
    "     'audios_names':names_rr1,\n",
    "    'audios_contents': content_rr1,\n",
    "    'stims_names': stims_names,\n",
    "    'blocks':blocks,\n",
    "    'conditions':expcond2,\n",
    "    'stim_AR': ars2,\n",
    "    'short_names':shorts2}\n",
    "\n",
    "df1 = pd.DataFrame.from_dict(dico)\n",
    "\n",
    "#################################\n",
    "# get names and contents for RR2#\n",
    "################################\n",
    "names_rr2 = []\n",
    "content_rr2 = []\n",
    "stims_names3 = []\n",
    "conds3 = []\n",
    "blocks3 = []\n",
    "expcond3 = []\n",
    "ars3 = []\n",
    "shorts3 = []\n",
    "for num in range(len(RR2s)):\n",
    "    curb2 = RR2s[num]['trial_id'][-1]\n",
    "    names_rr2.append('rr2_'+str(num+1)+'.wav')\n",
    "    content_rr2.append(RR2s[num]['response'])\n",
    "    stims_names3.append(RR2s[num]['stim_name'])\n",
    "    conds3.append('r&r2')\n",
    "    blocks3.append(curb2)\n",
    "    expcond3.append(df2.loc[df2[\"blocks\"]==str(curb2)]['conditions'].values[0])\n",
    "    ars3.append(np.nan)\n",
    "    shorts3.append(np.nan)\n",
    "\n",
    "\n",
    "dico3 = {\n",
    "    'trial_type':conds3,\n",
    "     'audios_names':names_rr2,\n",
    "    'audios_contents': content_rr2,\n",
    "    'stims_names': stims_names3,\n",
    "    'blocks':blocks3,\n",
    "    'conditions':expcond3,\n",
    "    'stim_AR': ars3,\n",
    "    'short_names':shorts3}\n",
    "\n",
    "df3 = pd.DataFrame.from_dict(dico3)\n",
    "\n",
    "#######################\n",
    "# concatenate all data#\n",
    "#######################\n",
    "alldata = pd.concat((df1,df2,df3)).reset_index()\n",
    "\n",
    "############################################################\n",
    "# add experimental conditions based on filtering properties#\n",
    "############################################################\n",
    "speeds = []\n",
    "filterings = []\n",
    "for i in range(len(alldata)):\n",
    "    curcond = alldata.iloc[i]['conditions']\n",
    "    filterings.append(conversion[curcond].split('_')[1])\n",
    "    speeds.append(conversion[curcond].split('_')[0])\n",
    "alldata['speed'] = speeds\n",
    "alldata['filtering'] = filterings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c2e4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get behavioral performance for gap in speech\n",
    "gap_reps = [i['sound'].split('/')[1].split('.')[0] for i in GAPs]\n",
    "perc_correct  = (np.sum([1 if i == 'good' else 0 for i in gap_reps])/len(gap_reps))*100\n",
    "print('Subject performance on gap trials: '+str(np.round(perc_correct,2))+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e02e044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save individual dataframe\n",
    "finaldat = alldata[['index', 'trial_type', 'audios_names','short_names', 'stims_names','blocks', 'conditions', 'stim_AR', 'speed', 'filtering']]\n",
    "outpathOne = \"C:\\\\Users\\\\Jeremy\\\\Desktop\\\\CONVERGENCE3_DATA_ANALYSIS\\\\data_prolific\\\\INDIVIDUAL\\\\\"+suj+\"\\\\INFO\\\\\"\n",
    "if not os.path.exists(outpathOne):\n",
    "    os.makedirs(outpathOne)  \n",
    "\n",
    "finaldat.to_csv(outpathOne+suj+\"_info.csv\", index = None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fda05b",
   "metadata": {},
   "source": [
    "# Create audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96831c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the folder for the audio files if it does not exist\n",
    "audio_outpath = \"C:\\\\Users\\\\Jeremy\\\\Desktop\\\\CONVERGENCE3_DATA_ANALYSIS\\\\data_prolific\\\\INDIVIDUAL\\\\\"+suj+\"\\\\audio_responses\\\\\"\n",
    "if not os.path.exists(audio_outpath):\n",
    "    os.makedirs(audio_outpath)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b960555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate all the names of the audio files\n",
    "final_names = alldata['audios_names'].values\n",
    "# aggregate all the audio files\n",
    "final_audio = alldata['audios_contents'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c6da2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate each succession of weird characters into .wav file\n",
    "for i,(name,audio) in enumerate(zip(final_names,final_audio)):\n",
    "    decodedData = base64.b64decode(audio)\n",
    "    webmfile = audio_outpath+\"temp.webm\"\n",
    "    with open(webmfile, 'wb') as file:\n",
    "           file.write(decodedData)\n",
    "    newtempath = str(webmfile).replace(os.path.sep, '/')\n",
    "    newfinalfilepath = str(audio_outpath+name).replace(os.path.sep, '/')\n",
    "    curcommand = 'ffmpeg -i '+newtempath+' ' + newfinalfilepath\n",
    "    os.system(curcommand)\n",
    "    os.remove(audio_outpath+\"temp.webm\") \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "423965c5",
   "metadata": {},
   "source": [
    "# other way of doing it but a slightly more bug prone due to system files\n",
    "# Translate each succession of weird characters into .wav file\n",
    "for i,(name,audio) in enumerate(zip(final_names,final_audio)):\n",
    "    decodedData = base64.b64decode(audio)\n",
    "    webmfile = audio_outpath+\"temp.webm\"\n",
    "    with open(webmfile, 'wb') as file:\n",
    "           file.write(decodedData)\n",
    "\n",
    "    ff = FFmpeg(\n",
    "           # executable = 'C:/Program Files/ffmpeg-2020/bin/ffmpeg.exe',\n",
    "            inputs={audio_outpath+'temp.webm':None},\n",
    "            outputs = {audio_outpath+name :'-c:a pcm_f32le'})\n",
    "    ff.cmd\n",
    "    ff.run()\n",
    "    os.remove(audio_outpath+\"temp.webm\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c91fac3",
   "metadata": {},
   "source": [
    "# Create webmaus files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc166cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine path for webmauss files\n",
    "outpath = \"C:\\\\Users\\\\Jeremy\\\\Desktop\\\\CONVERGENCE3_DATA_ANALYSIS\\\\data_prolific\\\\INDIVIDUAL\\\\\"+suj+\"\\\\webmauss\\\\\"\n",
    "inpath = \"C:\\\\Users\\\\Jeremy\\\\Desktop\\\\CONVERGENCE3_DATA_ANALYSIS\\\\data_prolific\\\\INDIVIDUAL\\\\\"+suj+\"\\\\audio_responses\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c0e80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create for each audio file, a text file with exactly the same name (except the end)\n",
    "# write in each .txt file the transcription of each sentence\n",
    "\n",
    "# loop across all audio files\n",
    "for i in range(len(alldata)): \n",
    "    # get name of each audi file\n",
    "    name = alldata.iloc[i]['audios_names'].split('.wav')[0]\n",
    "    # get transcription of each sentence\n",
    "    transcript = alldata.iloc[i]['stims_names']\n",
    "    # get .wav file and copy it to new directory\n",
    "    if not os.path.exists(outpath):\n",
    "        os.makedirs(outpath)  \n",
    "    shutil.copy(inpath+ name+'.wav', outpath+name+'.wav')\n",
    "    # create the .txt file containing the written sentence\n",
    "    with open(outpath+ name +'.txt', 'w') as f:\n",
    "        f.write(transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f820b5",
   "metadata": {},
   "source": [
    "# Import .wav and .txt file within the web service web mauss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e15f0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go to --> https://clarin.phonetik.uni-muenchen.de/BASWebServices/interface\n",
    "# click --> Pipeline without ASR\n",
    "# Pipeline name (required) --> select: G2P—>MAUS —>PHO2SYL \n",
    "# Language (required) -->  select: English (GB)\n",
    "# Output format (required) --> select: Praat (.TextGrid)\n",
    "\n",
    "# drop all audio and text files in the top rectangle (ctrl+a to select all within you audio folder)\n",
    "# run the web service\n",
    "# download the zip folder containing the .TextGrid files\n",
    "# extract them within the folder of origin of the audio and txt files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5ffe11",
   "metadata": {},
   "source": [
    "# Retrieve duration and number of linguistic units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7765a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(outpathOne +suj+\"_info.csv\")\n",
    "gridpath =  \"C:\\\\Users\\\\Jeremy\\\\Desktop\\\\CONVERGENCE3_DATA_ANALYSIS\\\\data_prolific\\\\INDIVIDUAL\\\\\"+suj+\"\\\\webmauss\\\\\"\n",
    "\n",
    "assert(len(os.listdir(gridpath))==240)\n",
    "\n",
    "\n",
    "full_durations = []\n",
    "for i in range(len(df)):\n",
    "    file = df.iloc[i]['audios_names']\n",
    "    x, sr = sf.read(gridpath+file)\n",
    "    \n",
    "    #print(len(x))\n",
    "    # get duration of the file\n",
    "    full_durations.append(len(x)/sr)\n",
    "# add lenght to the dataframe\n",
    "df['full_duration'] = full_durations\n",
    "# select only textgrid files\n",
    "all_files = os.listdir(gridpath)  \n",
    "grid_files = natsorted( list(filter(lambda f: f.endswith('.TextGrid'), all_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1db765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically extract information from the TextGrid files\n",
    "# select tiers containing number of words ,syllables and phonemes\n",
    "nb_sylls = []\n",
    "nb_phons = []\n",
    "nb_words = []\n",
    "len_sil = []\n",
    "names = []\n",
    "syll_dur = []\n",
    "#loop across files\n",
    "for i in range(len(df)):\n",
    "    file = df.iloc[i]['audios_names'].split('.wav')[0] + '.TextGrid'\n",
    "    if os.path.exists(gridpath+file):\n",
    "        grid = textgrids.TextGrid(gridpath+file)\n",
    "\n",
    "        # retrieve number of words\n",
    "        words = []\n",
    "        for i in (grid['ORT-MAU']):\n",
    "            if i.text != '':\n",
    "                words.append(i.text)\n",
    "        nb_words.append(len(words))\n",
    "\n",
    "        # retrieve number of syllables\n",
    "        sylls = []\n",
    "        syllsdur = []\n",
    "\n",
    "        for i in (grid['MAS']):\n",
    "            if i.text != '<p:>':\n",
    "                sylls.append(i.text)\n",
    "                syllsdur.append(i.xmax -i.xmin)\n",
    "        nb_sylls.append(len(sylls))\n",
    "        syll_dur.append(np.sort(syllsdur)[::-1][0:3])\n",
    "        names.append(file.split(\".\")[0])\n",
    "\n",
    "        # retrieve number of phonemes\n",
    "        phons = []\n",
    "        for i in (grid['MAU']):\n",
    "            if i.text != '<p:>':\n",
    "                phons.append(i.text)\n",
    "        nb_phons.append(len(phons))\n",
    "\n",
    "        # retrieve the total duration of silent part within each file\n",
    "        silences = []\n",
    "        for i in (grid['MAS']):\n",
    "            if i.text == '<p:>':\n",
    "                silences.append(i.xmax -i.xmin)\n",
    "        len_sil.append(np.sum(np.asarray(silences)))\n",
    "    else:\n",
    "        nb_sylls.append(np.nan)\n",
    "        nb_phons.append(np.nan)\n",
    "        nb_words.append(np.nan)\n",
    "        len_sil.append(np.nan)\n",
    "\n",
    "# adding nb of linguist unit in the dataframe\n",
    "df['nb_words'] = nb_words\n",
    "df['nb_sylls'] = nb_sylls\n",
    "df['nb_phons'] = nb_phons\n",
    "df['silent_duration'] = len_sil\n",
    "df['phonation_time'] = df['full_duration'].values - df['silent_duration'].values\n",
    "df['articulation rate'] = df['nb_sylls'].values/df['phonation_time'].values\n",
    "#df.to_csv(outpath+'info_final2.csv', index =None)\n",
    "\n",
    "#df2.to_csv(outpath+'webmausserrors.csv', index =None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457af5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.loc[df['trial_type']=='conv'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4908f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "arcs = []\n",
    "for i in range(len(df3)):\n",
    "    c = df3.iloc[i]['conditions']\n",
    "    arc = df.loc[(df['trial_type']==\"r&r1\")&(df['conditions']==c)]['articulation rate'].mean()\n",
    "    arcs.append(arc)\n",
    "df3['baseline_AR'] = arcs\n",
    "df3['absdiff'] = abs(df3['baseline_AR'] - df3['articulation rate'])\n",
    "df3['subj'] = np.repeat(suj,len(df3))\n",
    "df3.to_csv(\"CONVERGENCE3_DATA_ANALYSIS\\\\data_prolific\\\\FOR_R\\\\\"+suj+'_convergence.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735cdcf5",
   "metadata": {},
   "source": [
    "# Once all participants data have been processed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10e7ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mega dataframe for r analysis\n",
    "rpath = \"\\\\CONVERGENCE3_DATA_ANALYSIS\\\\data_prolific\\\\FOR_R\\\\\"\n",
    "files = os.listdir(rpath)\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dc62e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigos = []\n",
    "\n",
    "for file in files:\n",
    "    dt = pd.read_csv(rpath+file)\n",
    "    bigos.append(dt)\n",
    "bg = pd.concat(bigos)\n",
    "bg.to_csv(\"df_for_r_analysis.csv\",index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

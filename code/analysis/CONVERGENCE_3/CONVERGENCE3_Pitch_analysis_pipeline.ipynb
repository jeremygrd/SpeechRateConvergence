{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995bf198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from natsort import natsorted\n",
    "import base64\n",
    "import os\n",
    "import shutil\n",
    "import soundfile as sf\n",
    "from natsort import natsorted\n",
    "import textract\n",
    "import textgrids\n",
    "import json\n",
    "from dtaidistance import dtw\n",
    "import pitch_squeezer as ps\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eded85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list files in the folder containing all individual participant file\n",
    "sujs = os.listdir(\"\\\\CONVERGENCE3_DATA_ANALYSIS\\\\data_prolific\\\\RAW\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d87a5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sujs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feed35ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the subject you are going to work with\n",
    "suj = 'subj01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900d42b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"\\\\CONVERGENCE3_DATA_ANALYSIS\\\\data_prolific\\\\RAW\\\\\"+suj+\".txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290a47d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data as bytes\n",
    "text = textract.process(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c90481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data by components 10 is training (should be 11 in your data as I added a component)\n",
    "len(text.splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f31a040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "trainingdata = json.loads(text.splitlines()[11].decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73184305",
   "metadata": {},
   "source": [
    "# Extract RAW DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49df41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# CONCATENATE DATA from all 4 blocks#\n",
    "#####################################\n",
    "\n",
    "block1data = json.loads(text.splitlines()[12].decode('utf-8'))\n",
    "block2data = json.loads(text.splitlines()[13].decode('utf-8'))\n",
    "block3data = json.loads(text.splitlines()[14].decode('utf-8'))\n",
    "block4data = json.loads(text.splitlines()[15].decode('utf-8'))\n",
    "allblocks = np.concatenate((block1data,block2data,block3data,block4data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9818e276",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# create containers for each subtype of trial#\n",
    "##############################################\n",
    "RR1s =[]\n",
    "GAPs = []\n",
    "CONVs = []\n",
    "RR2s = []\n",
    "\n",
    "# retrive trials based on their id\n",
    "trial_types = [['read&repeat1block1','read&repeat1block2','read&repeat1block3','read&repeat1block4'],\n",
    "               ['gap_answerblock1','gap_answerblock2','gap_answerblock3','gap_answerblock4'],\n",
    "               ['convergenceblock1','convergenceblock2','convergenceblock3','convergenceblock4'],\n",
    "               ['read&repeat2block1','read&repeat2block2','read&repeat2block3','read&repeat2block4']]\n",
    "trial_containers = [RR1s, GAPs,CONVs,RR2s]\n",
    "\n",
    "for num,trial in enumerate(trial_types):\n",
    "    for numi in range(len(allblocks)):\n",
    "        try:\n",
    "            if allblocks[numi]['trial_id'] in trial:\n",
    "                trial_containers[num].append(allblocks[numi])\n",
    "        except: \n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5e68b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# make sure we have the desired number of trials per subtype#\n",
    "#############################################################\n",
    "\n",
    "assert(len(RR1s)==24) #6*4\n",
    "assert(len(RR2s)==24) #6*4\n",
    "assert(len(CONVs)==32) # 8*4\n",
    "\n",
    "# /!\\ if there is an error it means that the numbers chosen for the block trials are not the good ones\n",
    "# it can happen when participants reload some components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b953025c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in presented stimuli properties you can look on the github repo \n",
    "stim_info = pd.read_csv(\"CONVERGENCE3\\\\STIMULI\\\\stimuli_AR.csv\")\n",
    "# create dictionnary to convert filtering properties to experimental conditions\n",
    "conversion = {  '5.5_Inf': 'Normal_temporal',\n",
    "                'Inf_0.35': 'Normal_spectral' ,  \n",
    "                '23_Inf': 'Fast_temporal',\n",
    "                'Inf_1.5': 'Fast_spectral'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f0a778",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# get names and contents for CONVERGENCE#\n",
    "#########################################\n",
    "\n",
    "names_conv = []\n",
    "content_conv = []\n",
    "stims_namesconv = []\n",
    "conds2 = []\n",
    "blocks2 = []\n",
    "expcond = []\n",
    "ars = []\n",
    "shorts = []\n",
    "for num in range(len(CONVs)):\n",
    "    # get current condition\n",
    "    curxcond = CONVs[num]['presented_stim'].split('/')[1].split('filter_')[1]\n",
    "    # get current speed\n",
    "    spee = conversion[curxcond].split('_')[0]\n",
    "    # get AR from presented stim\n",
    "    curar = stim_info.loc[(stim_info['sentences'] == CONVs[num]['stimulus'].split(\"25px\\'>\")[1].split(\"</p>\")[0].lower())&(stim_info['speed'] == spee )]['articulation_rate'].values[0]\n",
    "    names_conv.append('conv_'+str(num+1)+'.wav')\n",
    "    content_conv.append(CONVs[num]['response'])\n",
    "    stims_namesconv.append(CONVs[num]['stimulus'].split(\"25px\\'>\")[1].split(\"</p>\")[0])\n",
    "    conds2.append('conv')\n",
    "    blocks2.append(CONVs[num]['trial_id'][-1])\n",
    "    expcond.append(curxcond)\n",
    "    ars.append(curar)\n",
    "    shorts.append(stim_info.loc[(stim_info['sentences'] == CONVs[num]['stimulus'].split(\"25px\\'>\")[1].split(\"</p>\")[0].lower())&(stim_info['speed'] == spee )]['short_names'].values[0])\n",
    "\n",
    "dico2 = {\n",
    "    'trial_type':conds2,\n",
    "     'audios_names':names_conv,\n",
    "    'audios_contents': content_conv,\n",
    "    'stims_names': stims_namesconv,\n",
    "    'blocks': blocks2,\n",
    "    'conditions':expcond,\n",
    "    'stim_AR': ars,\n",
    "    'short_names':shorts}\n",
    "df2 = pd.DataFrame.from_dict(dico2)\n",
    "\n",
    "\n",
    "#################################\n",
    "# get names and contents for RR1#\n",
    "#################################\n",
    "\n",
    "names_rr1 = []\n",
    "content_rr1 = []\n",
    "stims_names = []\n",
    "conds = []\n",
    "blocks = []\n",
    "expcond2 = []\n",
    "ars2 =[]\n",
    "shorts2 = []\n",
    "for num in range(len(RR1s)):\n",
    "    curb = RR1s[num]['trial_id'][-1]\n",
    "    names_rr1.append('rr1_'+str(num+1)+'.wav')\n",
    "    content_rr1.append(RR1s[num]['response'])\n",
    "    stims_names.append(RR1s[num]['stim_name'])\n",
    "    conds.append('r&r1')\n",
    "    blocks.append(curb)\n",
    "    expcond2.append(df2.loc[df2[\"blocks\"]==str(curb)]['conditions'].values[0])\n",
    "    ars2.append(np.nan)\n",
    "    shorts2.append(np.nan)\n",
    "\n",
    "dico = {\n",
    "    'trial_type':conds,\n",
    "     'audios_names':names_rr1,\n",
    "    'audios_contents': content_rr1,\n",
    "    'stims_names': stims_names,\n",
    "    'blocks':blocks,\n",
    "    'conditions':expcond2,\n",
    "    'stim_AR': ars2,\n",
    "    'short_names':shorts2}\n",
    "\n",
    "df1 = pd.DataFrame.from_dict(dico)\n",
    "\n",
    "#################################\n",
    "# get names and contents for RR2#\n",
    "################################\n",
    "names_rr2 = []\n",
    "content_rr2 = []\n",
    "stims_names3 = []\n",
    "conds3 = []\n",
    "blocks3 = []\n",
    "expcond3 = []\n",
    "ars3 = []\n",
    "shorts3 = []\n",
    "for num in range(len(RR2s)):\n",
    "    curb2 = RR2s[num]['trial_id'][-1]\n",
    "    names_rr2.append('rr2_'+str(num+1)+'.wav')\n",
    "    content_rr2.append(RR2s[num]['response'])\n",
    "    stims_names3.append(RR2s[num]['stim_name'])\n",
    "    conds3.append('r&r2')\n",
    "    blocks3.append(curb2)\n",
    "    expcond3.append(df2.loc[df2[\"blocks\"]==str(curb2)]['conditions'].values[0])\n",
    "    ars3.append(np.nan)\n",
    "    shorts3.append(np.nan)\n",
    "\n",
    "\n",
    "dico3 = {\n",
    "    'trial_type':conds3,\n",
    "     'audios_names':names_rr2,\n",
    "    'audios_contents': content_rr2,\n",
    "    'stims_names': stims_names3,\n",
    "    'blocks':blocks3,\n",
    "    'conditions':expcond3,\n",
    "    'stim_AR': ars3,\n",
    "    'short_names':shorts3}\n",
    "\n",
    "df3 = pd.DataFrame.from_dict(dico3)\n",
    "\n",
    "#######################\n",
    "# concatenate all data#\n",
    "#######################\n",
    "alldata = pd.concat((df1,df2,df3)).reset_index()\n",
    "\n",
    "############################################################\n",
    "# add experimental conditions based on filtering properties#\n",
    "############################################################\n",
    "speeds = []\n",
    "filterings = []\n",
    "for i in range(len(alldata)):\n",
    "    curcond = alldata.iloc[i]['conditions']\n",
    "    filterings.append(conversion[curcond].split('_')[1])\n",
    "    speeds.append(conversion[curcond].split('_')[0])\n",
    "alldata['speed'] = speeds\n",
    "alldata['filtering'] = filterings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6798c084",
   "metadata": {},
   "source": [
    "### Here you can modify the cell below to compute the performance per condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c2e4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get behavioral performance for gap in speech\n",
    "gap_reps = [i['sound'].split('/')[1].split('.')[0] for i in GAPs]\n",
    "gaps_conds = [i['stim_presented'].split('/')[1].split('/')[0] for i in GAPs]\n",
    "perc_correct  = (np.sum([1 if i == 'good' else 0 for i in gap_reps])/len(gap_reps))*100\n",
    "print('Subject performance on gap trials: '+str(np.round(perc_correct,2))+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e02e044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save individual dataframe\n",
    "finaldat = alldata[['index', 'trial_type', 'audios_names','short_names', 'stims_names','blocks', 'conditions', 'stim_AR', 'speed', 'filtering']]\n",
    "\n",
    "\n",
    "outpathOne = \"CONVERGENCE3_DATA_ANALYSIS\\\\data_prolific\\\\INDIVIDUAL\\\\\"+suj+\"\\\\INFO\\\\\"\n",
    "if not os.path.exists(outpathOne):\n",
    "    os.makedirs(outpathOne)  \n",
    "\n",
    "finaldat.to_csv(outpathOne+suj+\"_info.csv\", index = None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fda05b",
   "metadata": {},
   "source": [
    "# Create audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96831c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the folder for the audio files if it does not exist\n",
    "audio_outpath = \"CONVERGENCE3_DATA_ANALYSIS\\\\data_prolific\\\\INDIVIDUAL\\\\\"+suj+\"\\\\audio_responses\\\\\"\n",
    "if not os.path.exists(audio_outpath):\n",
    "    os.makedirs(audio_outpath)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b960555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate all the names of the audio files\n",
    "final_names = alldata['audios_names'].values\n",
    "# aggregate all the audio files\n",
    "final_audio = alldata['audios_contents'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c6da2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate each succession of weird characters into .wav file\n",
    "for i,(name,audio) in enumerate(zip(final_names,final_audio)):\n",
    "    decodedData = base64.b64decode(audio)\n",
    "    webmfile = audio_outpath+\"temp.webm\"\n",
    "    with open(webmfile, 'wb') as file:\n",
    "           file.write(decodedData)\n",
    "    newtempath = str(webmfile).replace(os.path.sep, '/')\n",
    "    newfinalfilepath = str(audio_outpath+name).replace(os.path.sep, '/')\n",
    "    curcommand = 'ffmpeg -i '+newtempath+' ' + newfinalfilepath\n",
    "    os.system(curcommand)\n",
    "    os.remove(audio_outpath+\"temp.webm\") \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "423965c5",
   "metadata": {},
   "source": [
    "# other way of doing it but a slightly more bug prone due to system files\n",
    "# Translate each succession of weird characters into .wav file\n",
    "for i,(name,audio) in enumerate(zip(final_names,final_audio)):\n",
    "    decodedData = base64.b64decode(audio)\n",
    "    webmfile = audio_outpath+\"temp.webm\"\n",
    "    with open(webmfile, 'wb') as file:\n",
    "           file.write(decodedData)\n",
    "\n",
    "    ff = FFmpeg(\n",
    "           # executable = 'C:/Program Files/ffmpeg-2020/bin/ffmpeg.exe',\n",
    "            inputs={audio_outpath+'temp.webm':None},\n",
    "            outputs = {audio_outpath+name :'-c:a pcm_f32le'})\n",
    "    ff.cmd\n",
    "    ff.run()\n",
    "    os.remove(audio_outpath+\"temp.webm\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f792ff",
   "metadata": {},
   "source": [
    "# Extract Pith and pitch contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb6c4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load indivudual participant info dataframe\n",
    "curdata = pd.read_csv(\"CONVERGENCE3_DATA_ANALYSIS\\\\data_prolific\\\\INDIVIDUAL\\\\\"+suj+\"\\\\INFO\\\\\"+suj+\"_info.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75777acc",
   "metadata": {},
   "source": [
    "### Here you can have a look at sklearn to compute other metrics (e.g., cosine distance or euclidean distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cfefc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn --> https://scikit-learn.org/stable/modules/generated/sklearn.metrics.DistanceMetric.html\n",
    "\n",
    "# extract all features we need\n",
    "\n",
    "yourmeanF0s = []\n",
    "stimulimeanF0s = []\n",
    "Distscontours = []\n",
    "\n",
    "\n",
    "generalpath = \"C:\\\\Users\\\\Jeremy\\\\Documents\\\\RESEARCH\\\\BEHAVIOR_2.0\\\\jatos_win_java\\\\study_assets_root\\\\CONVERGENCE3\\\\audio\"\n",
    "individualparticipantpath    = \"C:\\\\Users\\\\Jeremy\\\\Desktop\\\\CONVERGENCE3_DATA_ANALYSIS\\\\data_prolific\\\\INDIVIDUAL\\\\subj23\\\\audio_responses\\\\\"\n",
    "\n",
    "for row in tqdm(range(len(curdata))):\n",
    "    # determine condition\n",
    "    curent_cond = curdata.iloc[row]['trial_type']    \n",
    "    # retrieve audio path for my voice\n",
    "    my_own = curdata.iloc[row]['audios_names']\n",
    "    participantpath = individualparticipantpath+my_own\n",
    "    \n",
    "    if curent_cond == 'conv':\n",
    "        # retieve audiopath for experimental stimuli\n",
    "        presented = curdata.iloc[row]['short_names']\n",
    "        cond = curdata.iloc[row]['conditions']    \n",
    "        final_name = 'filter_' +cond+'_frm01_' + presented\n",
    "        foldername = '\\\\filter_' +cond\n",
    "        finalpathexpstim = foldername +'\\\\'+ final_name+\".wav\"\n",
    "        exppath = generalpath+finalpathexpstim\n",
    "\n",
    "    # here in the case where the trial type is 'conv' we compute both metrics (mean F0 and F0 contour) \n",
    "    # for both experimental audio stim and participants' productions\n",
    "       # if no audio data (participants did not record something) just ad np.nan\n",
    "        try: \n",
    "             # this for experiment stimuli\n",
    "            #loading and computing FO from experimental stimuli\n",
    "            f0, if0exp = ps.track_pitch(exppath, frame_rate=200)\n",
    "            meanf0exp = np.mean(if0exp,0)\n",
    "\n",
    "            # this for individual participant\n",
    "            f0, if0 = ps.track_pitch(participantpath, frame_rate=200)\n",
    "            meanf0participant = np.mean(if0,0)\n",
    "\n",
    "            # Dynamic Time warping distance to compute distance between pitch contour\n",
    "            F0distance = dtw.distance(if0exp, if0)\n",
    "            # here you can also use another metric\n",
    "            # for instance you can pad the shortest signal with zeros and compute euclidean distance or cosine distance\n",
    "            Distscontours.append(F0distance)\n",
    "            stimulimeanF0s.append(meanf0exp)\n",
    "            yourmeanF0s.append(meanf0participant)\n",
    "\n",
    "        except:\n",
    "            f0, if0exp = ps.track_pitch(exppath, frame_rate=200)\n",
    "            meanf0exp = np.mean(if0exp,0)\n",
    "            stimulimeanF0s.append(meanf0exp)\n",
    "            yourmeanF0s.append(np.nan)\n",
    "            Distscontours.append(np.nan)\n",
    "            \n",
    "    # here in the case where the trial type is 'r&r1' or 'r&r2' we just compute un metric (mean F0) \n",
    "    # and only for participants' productions as the experimental stimuli were presented as written forms\n",
    "    else:\n",
    "        try: \n",
    "            # this for individual participant\n",
    "            f0, if0 = ps.track_pitch(participantpath, frame_rate=200)\n",
    "            meanf0participant = np.mean(if0,0)\n",
    "            yourmeanF0s.append(meanf0participant)\n",
    "            # no FO from experimental stimuli because written stimuli\n",
    "            stimulimeanF0s.append(np.nan)\n",
    "            # No distance because only one audio file\n",
    "            Distscontours.append(np.nan)\n",
    "        except:\n",
    "            stimulimeanF0s.append(np.nan)\n",
    "            yourmeanF0s.append(np.nan)\n",
    "            Distscontours.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a232dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the F0 stims and F0 stim pitch contour distance \n",
    "curdata['meanF0_stim'] = stimulimeanF0s\n",
    "curdata['meanF0_subj'] = yourmeanF0s\n",
    "curdata['pitchcontour_dist'] = Distscontours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457af5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the convergence trial \n",
    "df3 = curdata.loc[curdata['trial_type']=='conv'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4908f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute baseline F0\n",
    "arcs = []\n",
    "for i in range(len(df3)):\n",
    "    c = df3.iloc[i]['conditions']\n",
    "    arc = curdata.loc[(curdata['trial_type']==\"r&r1\")&(curdata['conditions']==c)]['meanF0_subj'].mean()\n",
    "    arcs.append(arc)\n",
    "# add the mean F0 to the dataframe\n",
    "df3['baseline_F0_subj'] = arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8ff43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# abs of difference between stim F0 and subject mean F0\n",
    "df3['absdiff'] = abs(df3['meanF0_stim'] - df3['meanF0_subj'])\n",
    "df3['subj'] = np.repeat(suj,len(df3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6e9b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv(\"CONVERGENCE3_DATA_ANALYSIS\\\\data_prolific\\\\INDIVIDUAL\\\\\"+suj+\"\\\\INFO\\\\\"+suj+\"_infoF0.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
